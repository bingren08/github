{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13128.0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "headers = {'Accept':'*/*','Accept-Encoding':'gzip, deflate','Accept-Language':'zh-CN,zh;q=0.9','Connection':'keep-alive','User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.79 Safari/537.36'          }\n",
    "count = float(Soup(requests.get('http://zdb.pedaily.cn/inv/',headers = headers).text, \"lxml\").find('span',class_='total').text)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codecs import open \n",
    "\n",
    "def save_data(path,data='',mode='a+',encoding='utf-8'):\n",
    "    with open(path,mode=mode,encoding=encoding) as f:\n",
    "        f.write(data)\n",
    "\n",
    "def parse_info(soup):\n",
    "    info =soup.find('div',class_='info').text\n",
    "    info = info.replace(u'年','-').replace(u'月','-').replace(u'日','')\n",
    "    company =soup.find('dt',class_='company').text.replace(u',','，')\n",
    "    industry=soup.find('dt',class_='industry').text\n",
    "    #money=soup.find('dt',class_='money').text    \n",
    "    r=soup.find('span',class_='r')\n",
    "    r=r.text if r else ''\n",
    "    d=soup.find('span',class_='d')\n",
    "    d=d.text if d else ''\n",
    "    m=soup.find('span',class_='m')\n",
    "    m=m.text if m else ''    \n",
    "    group=soup.find('dt',class_='group').text\n",
    "    return [info,company,industry,r,m,d,group]    \n",
    "\n",
    "def parse_page(url,path):\n",
    "    soup = Soup(requests.get(url,headers= headers).text)\n",
    "    lis = soup.find('ul',id='inv-list').find_all('li')[1:]\n",
    "    for infos in lis:\n",
    "        #print(parse_info(infos))\n",
    "        data = parse_info(infos)\n",
    "        data.append('\\r\\n')\n",
    "        save_data(path,','.join(data))\n",
    "    \n",
    "save_path = '/home/git/PycharmProjects/github/jupyter/data/inv.csv'\n",
    "#parse_page('http://zdb.pedaily.cn/inv/y2017-p1/',save_path)\n",
    "save_data(save_path,','.join([u'投资时间',u'受资方',u'所属行业',u'VC阶段',u'投资金额',u'币种',u'投资方','\\r\\n']))\n",
    "parse_page('http://zdb.pedaily.cn/inv/y2017-p1/',save_path)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "save_data(save_path,','.join([u'投资时间',u'受资方',u'所属行业',u'VC阶段',u'投资金额',u'币种',u'投资方','\\r\\n']))\n",
    "for page in range(1,int(math.ceil(count/20))):\n",
    "    url = 'http://zdb.pedaily.cn/inv/y2017-p%i/' %page\n",
    "    parse_page(url,save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
